{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "q88XnFh5TmAI",
        "BGAR4q380gUP",
        "5qXr6LPW1s0E"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotaxtech/CUT/blob/main/CUT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## セットアップ"
      ],
      "metadata": {
        "id": "DU9Hqy_Kcy88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab上のGPUの確認．\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS75c2xNc1XS",
        "outputId": "74c13ea8-44cb-4b95-deb3-db606c6aa940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb  1 12:31:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MyDriveに移動し，workspaceディレクトリを作成．\n",
        "# Github(https://github.com/taesungp/contrastive-unpaired-translation)から該当リポジトリをクローン．\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/workspace\n",
        "%cd /content/drive/MyDrive/workspace\n",
        "!git clone https://github.com/taesungp/contrastive-unpaired-translation.git CUT"
      ],
      "metadata": {
        "id": "pD6N0AD2rzde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUTディレクトリに移動し，必要なライブラリをrequirements.txtのリストよりインストール．\n",
        "# 評価指標となるFIDのライブラリは別途インストールする必要あり．\n",
        "\n",
        "%cd /content/drive/MyDrive/workspace/CUT\n",
        "!pip install -r requirements.txt\n",
        "!pip install pytorch-fid"
      ],
      "metadata": {
        "id": "0kZk-RwXsrDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット\n"
      ],
      "metadata": {
        "id": "IiiKQeuStz42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUTディレクトリ直下にあるdatasetsディレクトリに以下のように自前のデータセットを配置する．原画像からラベル画像へ変換したい場合，trainA/testAには原画像，trainB/testBにはラベル画像を配置する．拡張子は特に記述はないが，pngかjpgの統一を推奨．\n",
        "```\n",
        "./datasets\n",
        "  └ image2label\n",
        "        ├ trainA\n",
        "        │  ├ image0000.png\n",
        "        │  ├ image0001.png\n",
        "        │  │    ・\n",
        "        │  │    ・\n",
        "        │  │    ・\n",
        "        │  └ imagexxxx.png\n",
        "        ├ trainB\n",
        "        ├ testA\n",
        "        └ testB\n",
        "```"
      ],
      "metadata": {
        "id": "IRIjqSBPuDPd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q88XnFh5TmAI"
      },
      "source": [
        "## 学習(Image2Label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMW5r8ZATnQC",
        "outputId": "06fd3b96-09fb-40c6-d8b8-4a1e5beccc23"
      },
      "source": [
        "# 以下のコードを実行すると，checkpointディレクトリが作成され，学習経過を示す画像と損失値，結合荷重が保存される．\n",
        "# 各パラメータについてはoptionsディレクトリのbase_option.pyとtrain_option.pyを参照.\n",
        "\n",
        "!python train.py \\\n",
        "  --dataroot ./datasets/image2label/ \\\n",
        "  --name img2label_CUT \\\n",
        "  --CUT_mode CUT \\\n",
        "  --n_epochs 50 \\\n",
        "  --n_epochs_decay 50 \\\n",
        "  --crop_size 256 \\\n",
        "  --batch_size 2 \\\n",
        "  --num_patches 64 \\\n",
        "  #--continue_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                 CUT_mode: CUT                           \n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "                    beta2: 0.999                         \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: True                          \t[default: False]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/soybean_img2label/ \t[default: placeholder]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: None                          \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "               easy_label: experiment_name               \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "          evaluation_freq: 5000                          \n",
            "        flip_equivariance: False                         \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "               lambda_GAN: 1.0                           \n",
            "               lambda_NCE: 1.0                           \n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cut                           \n",
            "                 n_epochs: 25                            \t[default: 200]\n",
            "           n_epochs_decay: 25                            \t[default: 200]\n",
            "               n_layers_D: 3                             \n",
            "                     name: soybean_img2label_CUT         \t[default: experiment_name]\n",
            "                    nce_T: 0.07                          \n",
            "                  nce_idt: True                          \n",
            "nce_includes_all_negatives_from_minibatch: False                         \n",
            "               nce_layers: 0,4,8,12,16                   \n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netF: mlp_sample                    \n",
            "                  netF_nc: 256                           \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "             no_antialias: False                         \n",
            "          no_antialias_up: False                         \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                    normD: instance                      \n",
            "                    normG: instance                      \n",
            "              num_patches: 256                           \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "          pretrained_name: None                          \n",
            "               print_freq: 100                           \n",
            "         random_scale_max: 3.0                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "stylegan2_G_num_downsampling: 1                             \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "model [CUTModel] was created\n",
            "The number of training images = 400\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f3fa6931e10>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3fa6931e10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3fa6931e10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/soybean_img2label_CUT/web...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "loading the model from ./checkpoints/soybean_img2label_CUT/latest_net_G.pth\n",
            "loading the model from ./checkpoints/soybean_img2label_CUT/latest_net_F.pth\n",
            "loading the model from ./checkpoints/soybean_img2label_CUT/latest_net_D.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "[Network F] Total number of parameters : 0.560 M\n",
            "[Network D] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "(epoch: 1, iters: 100, time: 0.244, data: 0.665) G_GAN: 0.271 D_real: 0.758 D_fake: 0.012 G: 2.718 NCE: 2.271 NCE_Y: 2.622 \n",
            "(epoch: 1, iters: 200, time: 0.309, data: 0.002) G_GAN: 0.687 D_real: 0.487 D_fake: 0.014 G: 3.908 NCE: 1.787 NCE_Y: 4.655 \n",
            "(epoch: 1, iters: 300, time: 0.352, data: 0.002) G_GAN: 1.022 D_real: 0.016 D_fake: 0.044 G: 3.047 NCE: 1.899 NCE_Y: 2.152 \n",
            "(epoch: 1, iters: 400, time: 0.381, data: 0.002) G_GAN: 0.692 D_real: 0.023 D_fake: 0.124 G: 2.978 NCE: 2.426 NCE_Y: 2.147 \n",
            "End of epoch 1 / 50 \t Time Taken: 175 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 2, iters: 100, time: 0.401, data: 0.168) G_GAN: 0.970 D_real: 0.022 D_fake: 0.036 G: 2.887 NCE: 1.640 NCE_Y: 2.195 \n",
            "(epoch: 2, iters: 200, time: 0.413, data: 0.002) G_GAN: 0.501 D_real: 0.030 D_fake: 0.222 G: 2.909 NCE: 1.727 NCE_Y: 3.089 \n",
            "(epoch: 2, iters: 300, time: 0.420, data: 0.002) G_GAN: 0.626 D_real: 0.053 D_fake: 0.090 G: 3.030 NCE: 2.003 NCE_Y: 2.805 \n",
            "(epoch: 2, iters: 400, time: 0.424, data: 0.002) G_GAN: 0.851 D_real: 0.014 D_fake: 0.011 G: 3.091 NCE: 1.978 NCE_Y: 2.502 \n",
            "End of epoch 2 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 3, iters: 100, time: 0.428, data: 0.212) G_GAN: 0.727 D_real: 0.145 D_fake: 0.011 G: 2.984 NCE: 1.831 NCE_Y: 2.682 \n",
            "(epoch: 3, iters: 200, time: 0.429, data: 0.002) G_GAN: 1.083 D_real: 0.010 D_fake: 0.012 G: 4.543 NCE: 1.769 NCE_Y: 5.150 \n",
            "(epoch: 3, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.959 D_real: 0.079 D_fake: 0.021 G: 2.874 NCE: 1.678 NCE_Y: 2.152 \n",
            "(epoch: 3, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.790 D_real: 0.025 D_fake: 0.200 G: 2.869 NCE: 1.955 NCE_Y: 2.203 \n",
            "End of epoch 3 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 4, iters: 100, time: 0.430, data: 0.213) G_GAN: 0.857 D_real: 0.017 D_fake: 0.030 G: 2.853 NCE: 1.751 NCE_Y: 2.241 \n",
            "(epoch: 4, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.553 D_real: 0.200 D_fake: 0.033 G: 2.457 NCE: 1.866 NCE_Y: 1.943 \n",
            "(epoch: 4, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.576 D_real: 0.266 D_fake: 0.072 G: 2.898 NCE: 1.840 NCE_Y: 2.805 \n",
            "(epoch: 4, iters: 400, time: 0.431, data: 0.002) G_GAN: 0.648 D_real: 0.284 D_fake: 0.045 G: 2.448 NCE: 1.534 NCE_Y: 2.066 \n",
            "End of epoch 4 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 5, iters: 100, time: 0.431, data: 0.167) G_GAN: 0.794 D_real: 0.092 D_fake: 0.112 G: 2.760 NCE: 2.013 NCE_Y: 1.920 \n",
            "(epoch: 5, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.818 D_real: 0.028 D_fake: 0.040 G: 2.964 NCE: 1.716 NCE_Y: 2.577 \n",
            "(epoch: 5, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.896 D_real: 0.046 D_fake: 0.152 G: 2.935 NCE: 1.822 NCE_Y: 2.258 \n",
            "(epoch: 5, iters: 400, time: 0.431, data: 0.002) G_GAN: 0.729 D_real: 0.249 D_fake: 0.010 G: 3.002 NCE: 1.838 NCE_Y: 2.708 \n",
            "saving the model at the end of epoch 5, iters 2000\n",
            "End of epoch 5 / 50 \t Time Taken: 174 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 6, iters: 100, time: 0.432, data: 0.255) G_GAN: 1.017 D_real: 0.006 D_fake: 0.000 G: 3.388 NCE: 1.850 NCE_Y: 2.891 \n",
            "(epoch: 6, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.866 D_real: 0.025 D_fake: 0.019 G: 2.699 NCE: 1.503 NCE_Y: 2.163 \n",
            "(epoch: 6, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.979 D_real: 0.004 D_fake: 0.000 G: 2.605 NCE: 1.432 NCE_Y: 1.819 \n",
            "(epoch: 6, iters: 400, time: 0.431, data: 0.002) G_GAN: 1.012 D_real: 0.004 D_fake: 0.000 G: 3.067 NCE: 1.357 NCE_Y: 2.754 \n",
            "End of epoch 6 / 50 \t Time Taken: 174 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 7, iters: 100, time: 0.431, data: 0.237) G_GAN: 0.995 D_real: 0.002 D_fake: 0.000 G: 3.062 NCE: 1.498 NCE_Y: 2.636 \n",
            "(epoch: 7, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.970 D_real: 0.005 D_fake: 0.001 G: 2.824 NCE: 1.451 NCE_Y: 2.255 \n",
            "(epoch: 7, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.982 D_real: 0.002 D_fake: 0.000 G: 3.017 NCE: 1.351 NCE_Y: 2.718 \n",
            "(epoch: 7, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.907 D_real: 0.008 D_fake: 0.007 G: 2.562 NCE: 1.368 NCE_Y: 1.942 \n",
            "End of epoch 7 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 8, iters: 100, time: 0.430, data: 0.183) G_GAN: 0.807 D_real: 0.028 D_fake: 0.051 G: 2.663 NCE: 1.465 NCE_Y: 2.247 \n",
            "(epoch: 8, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.996 D_real: 0.001 D_fake: 0.000 G: 3.000 NCE: 1.526 NCE_Y: 2.483 \n",
            "(epoch: 8, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.995 D_real: 0.001 D_fake: 0.000 G: 2.686 NCE: 1.488 NCE_Y: 1.894 \n",
            "(epoch: 8, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.999 D_real: 0.001 D_fake: 0.000 G: 2.990 NCE: 1.385 NCE_Y: 2.599 \n",
            "End of epoch 8 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 9, iters: 100, time: 0.430, data: 0.179) G_GAN: 1.014 D_real: 0.005 D_fake: 0.004 G: 3.347 NCE: 1.942 NCE_Y: 2.725 \n",
            "(epoch: 9, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.010 D_real: 0.001 D_fake: 0.000 G: 3.090 NCE: 1.372 NCE_Y: 2.788 \n",
            "(epoch: 9, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.992 D_real: 0.002 D_fake: 0.000 G: 3.064 NCE: 1.322 NCE_Y: 2.822 \n",
            "(epoch: 9, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.005 D_real: 0.001 D_fake: 0.000 G: 2.801 NCE: 1.332 NCE_Y: 2.261 \n",
            "End of epoch 9 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 10, iters: 100, time: 0.431, data: 0.229) G_GAN: 0.999 D_real: 0.001 D_fake: 0.001 G: 3.094 NCE: 1.318 NCE_Y: 2.873 \n",
            "(epoch: 10, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.980 D_real: 0.003 D_fake: 0.000 G: 2.598 NCE: 1.343 NCE_Y: 1.895 \n",
            "(epoch: 10, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.993 D_real: 0.001 D_fake: 0.000 G: 2.896 NCE: 1.399 NCE_Y: 2.407 \n",
            "(epoch: 10, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.860 D_real: 0.021 D_fake: 0.024 G: 2.830 NCE: 1.344 NCE_Y: 2.597 \n",
            "saving the model at the end of epoch 10, iters 4000\n",
            "End of epoch 10 / 50 \t Time Taken: 174 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 11, iters: 100, time: 0.431, data: 0.190) G_GAN: 0.997 D_real: 0.001 D_fake: 0.000 G: 2.881 NCE: 1.370 NCE_Y: 2.398 \n",
            "(epoch: 11, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.997 D_real: 0.001 D_fake: 0.000 G: 2.704 NCE: 1.423 NCE_Y: 1.990 \n",
            "(epoch: 11, iters: 300, time: 0.431, data: 0.002) G_GAN: 1.013 D_real: 0.001 D_fake: 0.000 G: 3.012 NCE: 1.414 NCE_Y: 2.584 \n",
            "(epoch: 11, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.762 D_real: 0.039 D_fake: 0.054 G: 2.494 NCE: 1.284 NCE_Y: 2.179 \n",
            "End of epoch 11 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 12, iters: 100, time: 0.431, data: 0.204) G_GAN: 1.012 D_real: 0.001 D_fake: 0.000 G: 2.966 NCE: 1.347 NCE_Y: 2.560 \n",
            "(epoch: 12, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.992 D_real: 0.003 D_fake: 0.001 G: 3.004 NCE: 1.303 NCE_Y: 2.722 \n",
            "(epoch: 12, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.987 D_real: 0.001 D_fake: 0.000 G: 2.636 NCE: 1.332 NCE_Y: 1.966 \n",
            "(epoch: 12, iters: 400, time: 0.431, data: 0.002) G_GAN: 0.954 D_real: 0.004 D_fake: 0.000 G: 3.945 NCE: 1.266 NCE_Y: 4.716 \n",
            "End of epoch 12 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 13, iters: 100, time: 0.431, data: 0.205) G_GAN: 1.014 D_real: 0.002 D_fake: 0.000 G: 2.707 NCE: 1.257 NCE_Y: 2.129 \n",
            "(epoch: 13, iters: 200, time: 0.431, data: 0.002) G_GAN: 1.000 D_real: 0.002 D_fake: 0.000 G: 3.306 NCE: 1.277 NCE_Y: 3.336 \n",
            "saving the latest model (epoch 13, total_iters 5000)\n",
            "soybean_img2label_CUT\n",
            "(epoch: 13, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.951 D_real: 0.005 D_fake: 0.002 G: 2.641 NCE: 1.285 NCE_Y: 2.097 \n",
            "(epoch: 13, iters: 400, time: 0.431, data: 0.002) G_GAN: 1.002 D_real: 0.001 D_fake: 0.001 G: 2.844 NCE: 1.283 NCE_Y: 2.401 \n",
            "End of epoch 13 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 14, iters: 100, time: 0.430, data: 0.229) G_GAN: 1.001 D_real: 0.004 D_fake: 0.002 G: 2.798 NCE: 1.274 NCE_Y: 2.321 \n",
            "(epoch: 14, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.994 D_real: 0.002 D_fake: 0.000 G: 2.796 NCE: 1.250 NCE_Y: 2.353 \n",
            "(epoch: 14, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.958 D_real: 0.161 D_fake: 1.441 G: 2.959 NCE: 1.248 NCE_Y: 2.753 \n",
            "(epoch: 14, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.994 D_real: 0.001 D_fake: 0.000 G: 2.867 NCE: 1.263 NCE_Y: 2.482 \n",
            "End of epoch 14 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 15, iters: 100, time: 0.430, data: 0.212) G_GAN: 0.938 D_real: 0.007 D_fake: 0.000 G: 3.777 NCE: 1.252 NCE_Y: 4.427 \n",
            "(epoch: 15, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.993 D_real: 0.002 D_fake: 0.000 G: 2.849 NCE: 1.248 NCE_Y: 2.464 \n",
            "(epoch: 15, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.999 D_real: 0.001 D_fake: 0.000 G: 2.623 NCE: 1.217 NCE_Y: 2.031 \n",
            "(epoch: 15, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.995 D_real: 0.002 D_fake: 0.000 G: 2.779 NCE: 1.226 NCE_Y: 2.343 \n",
            "saving the model at the end of epoch 15, iters 6000\n",
            "End of epoch 15 / 50 \t Time Taken: 174 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 16, iters: 100, time: 0.431, data: 0.242) G_GAN: 1.014 D_real: 0.005 D_fake: 0.001 G: 2.887 NCE: 1.222 NCE_Y: 2.524 \n",
            "(epoch: 16, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.991 D_real: 0.002 D_fake: 0.000 G: 2.993 NCE: 1.223 NCE_Y: 2.780 \n",
            "(epoch: 16, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.998 D_real: 0.001 D_fake: 0.000 G: 3.113 NCE: 1.228 NCE_Y: 3.003 \n",
            "(epoch: 16, iters: 400, time: 0.431, data: 0.002) G_GAN: 1.007 D_real: 0.001 D_fake: 0.000 G: 2.627 NCE: 1.294 NCE_Y: 1.946 \n",
            "End of epoch 16 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 17, iters: 100, time: 0.431, data: 0.185) G_GAN: 0.981 D_real: 0.003 D_fake: 0.000 G: 2.515 NCE: 1.239 NCE_Y: 1.827 \n",
            "(epoch: 17, iters: 200, time: 0.431, data: 0.002) G_GAN: 1.001 D_real: 0.001 D_fake: 0.000 G: 2.841 NCE: 1.229 NCE_Y: 2.453 \n",
            "(epoch: 17, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.998 D_real: 0.001 D_fake: 0.000 G: 2.906 NCE: 1.290 NCE_Y: 2.526 \n",
            "(epoch: 17, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.983 D_real: 0.004 D_fake: 0.001 G: 2.895 NCE: 1.289 NCE_Y: 2.534 \n",
            "End of epoch 17 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 18, iters: 100, time: 0.430, data: 0.229) G_GAN: 0.993 D_real: 0.001 D_fake: 0.000 G: 2.819 NCE: 1.269 NCE_Y: 2.383 \n",
            "(epoch: 18, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.979 D_real: 0.002 D_fake: 0.000 G: 2.544 NCE: 1.232 NCE_Y: 1.897 \n",
            "(epoch: 18, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.404 D_real: 0.264 D_fake: 0.187 G: 3.152 NCE: 2.162 NCE_Y: 3.334 \n",
            "(epoch: 18, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.081 D_real: 0.076 D_fake: 0.150 G: 3.316 NCE: 1.606 NCE_Y: 2.865 \n",
            "End of epoch 18 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 19, iters: 100, time: 0.430, data: 0.194) G_GAN: 0.354 D_real: 0.639 D_fake: 0.053 G: 2.349 NCE: 1.957 NCE_Y: 2.034 \n",
            "(epoch: 19, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.869 D_real: 0.094 D_fake: 0.026 G: 3.221 NCE: 2.231 NCE_Y: 2.472 \n",
            "(epoch: 19, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.894 D_real: 0.027 D_fake: 0.029 G: 3.920 NCE: 1.740 NCE_Y: 4.314 \n",
            "(epoch: 19, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.868 D_real: 0.015 D_fake: 0.010 G: 3.519 NCE: 1.808 NCE_Y: 3.495 \n",
            "End of epoch 19 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 20, iters: 100, time: 0.430, data: 0.200) G_GAN: 0.885 D_real: 0.004 D_fake: 0.034 G: 4.828 NCE: 2.341 NCE_Y: 5.545 \n",
            "(epoch: 20, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.949 D_real: 0.039 D_fake: 0.018 G: 3.088 NCE: 1.803 NCE_Y: 2.474 \n",
            "(epoch: 20, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.331 D_real: 0.658 D_fake: 0.014 G: 2.466 NCE: 1.908 NCE_Y: 2.363 \n",
            "(epoch: 20, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.058 D_real: 0.076 D_fake: 0.012 G: 3.285 NCE: 1.943 NCE_Y: 2.510 \n",
            "saving the model at the end of epoch 20, iters 8000\n",
            "End of epoch 20 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 21, iters: 100, time: 0.430, data: 0.216) G_GAN: 0.365 D_real: 0.428 D_fake: 0.028 G: 2.692 NCE: 1.849 NCE_Y: 2.806 \n",
            "(epoch: 21, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.977 D_real: 0.006 D_fake: 0.022 G: 3.057 NCE: 1.924 NCE_Y: 2.235 \n",
            "(epoch: 21, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.887 D_real: 0.212 D_fake: 0.033 G: 2.639 NCE: 1.761 NCE_Y: 1.744 \n",
            "(epoch: 21, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.165 D_real: 0.046 D_fake: 0.018 G: 3.252 NCE: 1.969 NCE_Y: 2.206 \n",
            "End of epoch 21 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 22, iters: 100, time: 0.430, data: 0.218) G_GAN: 1.097 D_real: 0.003 D_fake: 0.013 G: 3.660 NCE: 2.715 NCE_Y: 2.412 \n",
            "(epoch: 22, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.033 D_real: 0.005 D_fake: 0.001 G: 2.941 NCE: 1.392 NCE_Y: 2.424 \n",
            "(epoch: 22, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.034 D_real: 0.003 D_fake: 0.004 G: 3.157 NCE: 1.439 NCE_Y: 2.807 \n",
            "(epoch: 22, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.495 D_real: 0.064 D_fake: 0.328 G: 2.698 NCE: 2.012 NCE_Y: 2.394 \n",
            "End of epoch 22 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 23, iters: 100, time: 0.430, data: 0.220) G_GAN: 0.892 D_real: 0.019 D_fake: 0.030 G: 2.935 NCE: 1.580 NCE_Y: 2.506 \n",
            "(epoch: 23, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.074 D_real: 0.043 D_fake: 0.048 G: 3.359 NCE: 1.799 NCE_Y: 2.771 \n",
            "(epoch: 23, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.040 D_real: 0.008 D_fake: 0.005 G: 2.953 NCE: 1.815 NCE_Y: 2.011 \n",
            "(epoch: 23, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.927 D_real: 0.032 D_fake: 0.019 G: 3.455 NCE: 1.974 NCE_Y: 3.081 \n",
            "End of epoch 23 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 24, iters: 100, time: 0.429, data: 0.207) G_GAN: 0.382 D_real: 0.391 D_fake: 0.018 G: 2.398 NCE: 1.713 NCE_Y: 2.320 \n",
            "(epoch: 24, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.936 D_real: 0.015 D_fake: 0.010 G: 3.131 NCE: 2.156 NCE_Y: 2.232 \n",
            "(epoch: 24, iters: 300, time: 0.429, data: 0.002) G_GAN: 0.617 D_real: 0.401 D_fake: 0.101 G: 2.760 NCE: 1.870 NCE_Y: 2.415 \n",
            "(epoch: 24, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.808 D_real: 0.134 D_fake: 0.063 G: 3.105 NCE: 1.869 NCE_Y: 2.727 \n",
            "End of epoch 24 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 25, iters: 100, time: 0.429, data: 0.220) G_GAN: 0.557 D_real: 0.104 D_fake: 0.100 G: 3.357 NCE: 1.752 NCE_Y: 3.846 \n",
            "(epoch: 25, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.575 D_real: 0.062 D_fake: 0.380 G: 3.362 NCE: 2.320 NCE_Y: 3.254 \n",
            "(epoch: 25, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.718 D_real: 0.041 D_fake: 0.152 G: 3.100 NCE: 1.833 NCE_Y: 2.931 \n",
            "(epoch: 25, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.063 D_real: 0.005 D_fake: 0.018 G: 3.636 NCE: 2.476 NCE_Y: 2.670 \n",
            "saving the latest model (epoch 25, total_iters 10000)\n",
            "soybean_img2label_CUT\n",
            "saving the model at the end of epoch 25, iters 10000\n",
            "End of epoch 25 / 50 \t Time Taken: 174 sec\n",
            "learning rate = 0.0001923\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 26, iters: 100, time: 0.430, data: 0.192) G_GAN: 1.071 D_real: 0.027 D_fake: 0.063 G: 3.586 NCE: 1.844 NCE_Y: 3.186 \n",
            "(epoch: 26, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.773 D_real: 0.024 D_fake: 0.130 G: 2.978 NCE: 1.863 NCE_Y: 2.548 \n",
            "(epoch: 26, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.060 D_real: 0.046 D_fake: 0.013 G: 2.945 NCE: 1.598 NCE_Y: 2.172 \n",
            "(epoch: 26, iters: 400, time: 0.429, data: 0.002) G_GAN: 0.434 D_real: 0.206 D_fake: 0.075 G: 2.958 NCE: 2.080 NCE_Y: 2.970 \n",
            "End of epoch 26 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001846\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 27, iters: 100, time: 0.430, data: 0.202) G_GAN: 0.438 D_real: 0.071 D_fake: 0.231 G: 2.366 NCE: 1.631 NCE_Y: 2.226 \n",
            "(epoch: 27, iters: 200, time: 0.429, data: 0.002) G_GAN: 0.716 D_real: 0.029 D_fake: 0.118 G: 2.927 NCE: 1.836 NCE_Y: 2.586 \n",
            "(epoch: 27, iters: 300, time: 0.430, data: 0.001) G_GAN: 1.135 D_real: 0.027 D_fake: 0.036 G: 4.229 NCE: 1.861 NCE_Y: 4.329 \n",
            "(epoch: 27, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.630 D_real: 0.022 D_fake: 0.111 G: 2.681 NCE: 2.199 NCE_Y: 1.903 \n",
            "End of epoch 27 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001769\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 28, iters: 100, time: 0.430, data: 0.205) G_GAN: 0.968 D_real: 0.018 D_fake: 0.018 G: 3.123 NCE: 1.720 NCE_Y: 2.590 \n",
            "(epoch: 28, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.961 D_real: 0.011 D_fake: 0.002 G: 2.652 NCE: 1.479 NCE_Y: 1.903 \n",
            "(epoch: 28, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.996 D_real: 0.002 D_fake: 0.002 G: 2.965 NCE: 1.440 NCE_Y: 2.499 \n",
            "(epoch: 28, iters: 400, time: 0.429, data: 0.002) G_GAN: 1.002 D_real: 0.005 D_fake: 0.001 G: 3.049 NCE: 1.357 NCE_Y: 2.737 \n",
            "End of epoch 28 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001692\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 29, iters: 100, time: 0.430, data: 0.206) G_GAN: 1.028 D_real: 0.005 D_fake: 0.000 G: 3.085 NCE: 1.373 NCE_Y: 2.741 \n",
            "(epoch: 29, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.990 D_real: 0.004 D_fake: 0.000 G: 2.543 NCE: 1.313 NCE_Y: 1.793 \n",
            "(epoch: 29, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.985 D_real: 0.001 D_fake: 0.000 G: 2.626 NCE: 1.292 NCE_Y: 1.992 \n",
            "(epoch: 29, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.996 D_real: 0.002 D_fake: 0.000 G: 2.846 NCE: 1.318 NCE_Y: 2.383 \n",
            "End of epoch 29 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001615\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 30, iters: 100, time: 0.431, data: 0.177) G_GAN: 0.995 D_real: 0.002 D_fake: 0.000 G: 2.524 NCE: 1.291 NCE_Y: 1.768 \n",
            "(epoch: 30, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.007 D_real: 0.002 D_fake: 0.000 G: 2.886 NCE: 1.260 NCE_Y: 2.498 \n",
            "(epoch: 30, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.994 D_real: 0.001 D_fake: 0.000 G: 2.760 NCE: 1.294 NCE_Y: 2.239 \n",
            "(epoch: 30, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.996 D_real: 0.001 D_fake: 0.000 G: 3.070 NCE: 1.224 NCE_Y: 2.924 \n",
            "saving the model at the end of epoch 30, iters 12000\n",
            "End of epoch 30 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001538\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 31, iters: 100, time: 0.430, data: 0.166) G_GAN: 0.992 D_real: 0.002 D_fake: 0.000 G: 2.970 NCE: 1.224 NCE_Y: 2.733 \n",
            "(epoch: 31, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.998 D_real: 0.001 D_fake: 0.000 G: 3.044 NCE: 1.240 NCE_Y: 2.853 \n",
            "(epoch: 31, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.012 D_real: 0.002 D_fake: 0.000 G: 2.775 NCE: 1.278 NCE_Y: 2.247 \n",
            "(epoch: 31, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.990 D_real: 0.001 D_fake: 0.000 G: 2.893 NCE: 1.219 NCE_Y: 2.586 \n",
            "End of epoch 31 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001462\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 32, iters: 100, time: 0.430, data: 0.211) G_GAN: 0.992 D_real: 0.001 D_fake: 0.000 G: 2.787 NCE: 1.215 NCE_Y: 2.375 \n",
            "(epoch: 32, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.006 D_real: 0.000 D_fake: 0.000 G: 2.968 NCE: 1.219 NCE_Y: 2.706 \n",
            "(epoch: 32, iters: 300, time: 0.429, data: 0.002) G_GAN: 0.993 D_real: 0.002 D_fake: 0.001 G: 2.542 NCE: 1.262 NCE_Y: 1.835 \n",
            "(epoch: 32, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.998 D_real: 0.001 D_fake: 0.000 G: 2.607 NCE: 1.224 NCE_Y: 1.994 \n",
            "End of epoch 32 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001385\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 33, iters: 100, time: 0.430, data: 0.195) G_GAN: 0.994 D_real: 0.001 D_fake: 0.000 G: 2.807 NCE: 1.229 NCE_Y: 2.397 \n",
            "(epoch: 33, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.005 D_real: 0.001 D_fake: 0.000 G: 2.940 NCE: 1.245 NCE_Y: 2.626 \n",
            "(epoch: 33, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.997 D_real: 0.001 D_fake: 0.000 G: 2.891 NCE: 1.234 NCE_Y: 2.554 \n",
            "(epoch: 33, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.991 D_real: 0.001 D_fake: 0.001 G: 2.674 NCE: 1.227 NCE_Y: 2.139 \n",
            "End of epoch 33 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001308\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 34, iters: 100, time: 0.430, data: 0.209) G_GAN: 0.995 D_real: 0.001 D_fake: 0.000 G: 2.603 NCE: 1.255 NCE_Y: 1.961 \n",
            "(epoch: 34, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.983 D_real: 0.003 D_fake: 0.007 G: 2.908 NCE: 1.467 NCE_Y: 2.384 \n",
            "(epoch: 34, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.975 D_real: 0.004 D_fake: 0.006 G: 3.329 NCE: 1.514 NCE_Y: 3.193 \n",
            "(epoch: 34, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.996 D_real: 0.002 D_fake: 0.003 G: 2.844 NCE: 1.441 NCE_Y: 2.254 \n",
            "End of epoch 34 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001231\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 35, iters: 100, time: 0.430, data: 0.233) G_GAN: 0.977 D_real: 0.007 D_fake: 0.011 G: 2.781 NCE: 1.729 NCE_Y: 1.879 \n",
            "(epoch: 35, iters: 200, time: 0.430, data: 0.001) G_GAN: 1.012 D_real: 0.002 D_fake: 0.001 G: 2.808 NCE: 1.427 NCE_Y: 2.164 \n",
            "(epoch: 35, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.977 D_real: 0.001 D_fake: 0.000 G: 2.514 NCE: 1.317 NCE_Y: 1.757 \n",
            "(epoch: 35, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.714 D_real: 0.073 D_fake: 0.445 G: 2.764 NCE: 2.068 NCE_Y: 2.030 \n",
            "saving the model at the end of epoch 35, iters 14000\n",
            "End of epoch 35 / 50 \t Time Taken: 174 sec\n",
            "learning rate = 0.0001154\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 36, iters: 100, time: 0.430, data: 0.188) G_GAN: 1.088 D_real: 0.053 D_fake: 0.028 G: 3.135 NCE: 2.011 NCE_Y: 2.084 \n",
            "(epoch: 36, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.941 D_real: 0.009 D_fake: 0.032 G: 2.968 NCE: 1.721 NCE_Y: 2.333 \n",
            "(epoch: 36, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.675 D_real: 0.027 D_fake: 0.100 G: 2.741 NCE: 1.939 NCE_Y: 2.194 \n",
            "(epoch: 36, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.874 D_real: 0.014 D_fake: 0.093 G: 3.093 NCE: 2.299 NCE_Y: 2.138 \n",
            "End of epoch 36 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001077\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 37, iters: 100, time: 0.430, data: 0.157) G_GAN: 1.075 D_real: 0.034 D_fake: 0.030 G: 3.134 NCE: 1.603 NCE_Y: 2.515 \n",
            "(epoch: 37, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.731 D_real: 0.221 D_fake: 0.021 G: 3.174 NCE: 1.765 NCE_Y: 3.121 \n",
            "(epoch: 37, iters: 300, time: 0.429, data: 0.001) G_GAN: 0.939 D_real: 0.011 D_fake: 0.006 G: 2.912 NCE: 1.629 NCE_Y: 2.317 \n",
            "(epoch: 37, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.793 D_real: 0.009 D_fake: 0.111 G: 2.864 NCE: 1.909 NCE_Y: 2.234 \n",
            "End of epoch 37 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0001000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 38, iters: 100, time: 0.430, data: 0.211) G_GAN: 0.705 D_real: 0.031 D_fake: 0.079 G: 2.810 NCE: 1.579 NCE_Y: 2.631 \n",
            "(epoch: 38, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.834 D_real: 0.016 D_fake: 0.033 G: 2.990 NCE: 1.926 NCE_Y: 2.384 \n",
            "saving the latest model (epoch 38, total_iters 15000)\n",
            "soybean_img2label_CUT\n",
            "(epoch: 38, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.059 D_real: 0.024 D_fake: 0.017 G: 2.949 NCE: 1.686 NCE_Y: 2.095 \n",
            "(epoch: 38, iters: 400, time: 0.430, data: 0.001) G_GAN: 0.928 D_real: 0.014 D_fake: 0.020 G: 3.224 NCE: 2.047 NCE_Y: 2.544 \n",
            "End of epoch 38 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000923\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 39, iters: 100, time: 0.430, data: 0.193) G_GAN: 0.853 D_real: 0.007 D_fake: 0.023 G: 2.857 NCE: 1.705 NCE_Y: 2.302 \n",
            "(epoch: 39, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.716 D_real: 0.020 D_fake: 0.089 G: 2.832 NCE: 1.748 NCE_Y: 2.484 \n",
            "(epoch: 39, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.774 D_real: 0.357 D_fake: 0.019 G: 3.225 NCE: 1.645 NCE_Y: 3.257 \n",
            "(epoch: 39, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.002 D_real: 0.006 D_fake: 0.009 G: 2.958 NCE: 1.524 NCE_Y: 2.387 \n",
            "End of epoch 39 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000846\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 40, iters: 100, time: 0.430, data: 0.237) G_GAN: 0.937 D_real: 0.011 D_fake: 0.008 G: 2.616 NCE: 1.700 NCE_Y: 1.658 \n",
            "(epoch: 40, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.031 D_real: 0.006 D_fake: 0.002 G: 3.042 NCE: 1.732 NCE_Y: 2.288 \n",
            "(epoch: 40, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.000 D_real: 0.007 D_fake: 0.000 G: 2.882 NCE: 1.645 NCE_Y: 2.118 \n",
            "(epoch: 40, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.004 D_real: 0.004 D_fake: 0.000 G: 2.736 NCE: 1.370 NCE_Y: 2.092 \n",
            "saving the model at the end of epoch 40, iters 16000\n",
            "End of epoch 40 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000769\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 41, iters: 100, time: 0.430, data: 0.219) G_GAN: 1.005 D_real: 0.003 D_fake: 0.000 G: 2.782 NCE: 1.374 NCE_Y: 2.181 \n",
            "(epoch: 41, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.002 D_real: 0.001 D_fake: 0.000 G: 2.724 NCE: 1.350 NCE_Y: 2.094 \n",
            "(epoch: 41, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.005 D_real: 0.002 D_fake: 0.000 G: 2.683 NCE: 1.359 NCE_Y: 1.998 \n",
            "(epoch: 41, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.986 D_real: 0.003 D_fake: 0.000 G: 2.612 NCE: 1.324 NCE_Y: 1.927 \n",
            "End of epoch 41 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000692\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 42, iters: 100, time: 0.430, data: 0.198) G_GAN: 0.992 D_real: 0.002 D_fake: 0.000 G: 3.195 NCE: 1.316 NCE_Y: 3.090 \n",
            "(epoch: 42, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.005 D_real: 0.001 D_fake: 0.000 G: 2.662 NCE: 1.285 NCE_Y: 2.030 \n",
            "(epoch: 42, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.004 D_real: 0.002 D_fake: 0.000 G: 3.066 NCE: 1.275 NCE_Y: 2.849 \n",
            "(epoch: 42, iters: 400, time: 0.430, data: 0.001) G_GAN: 0.978 D_real: 0.002 D_fake: 0.000 G: 2.555 NCE: 1.263 NCE_Y: 1.890 \n",
            "End of epoch 42 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000615\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 43, iters: 100, time: 0.430, data: 0.200) G_GAN: 0.995 D_real: 0.001 D_fake: 0.000 G: 2.853 NCE: 1.289 NCE_Y: 2.426 \n",
            "(epoch: 43, iters: 200, time: 0.430, data: 0.001) G_GAN: 1.008 D_real: 0.002 D_fake: 0.000 G: 2.757 NCE: 1.284 NCE_Y: 2.215 \n",
            "(epoch: 43, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.000 D_real: 0.001 D_fake: 0.000 G: 2.810 NCE: 1.244 NCE_Y: 2.377 \n",
            "(epoch: 43, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.994 D_real: 0.001 D_fake: 0.000 G: 2.991 NCE: 1.278 NCE_Y: 2.716 \n",
            "End of epoch 43 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000538\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 44, iters: 100, time: 0.430, data: 0.200) G_GAN: 1.002 D_real: 0.001 D_fake: 0.000 G: 2.661 NCE: 1.234 NCE_Y: 2.083 \n",
            "(epoch: 44, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.849 D_real: 0.004 D_fake: 0.018 G: 2.760 NCE: 1.256 NCE_Y: 2.567 \n",
            "(epoch: 44, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.004 D_real: 0.002 D_fake: 0.000 G: 2.803 NCE: 1.215 NCE_Y: 2.381 \n",
            "(epoch: 44, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.005 D_real: 0.001 D_fake: 0.000 G: 2.470 NCE: 1.241 NCE_Y: 1.689 \n",
            "End of epoch 44 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000462\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 45, iters: 100, time: 0.430, data: 0.160) G_GAN: 0.997 D_real: 0.002 D_fake: 0.000 G: 3.882 NCE: 1.259 NCE_Y: 4.512 \n",
            "(epoch: 45, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.996 D_real: 0.001 D_fake: 0.000 G: 3.018 NCE: 1.248 NCE_Y: 2.796 \n",
            "(epoch: 45, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.983 D_real: 0.001 D_fake: 0.000 G: 2.506 NCE: 1.253 NCE_Y: 1.793 \n",
            "(epoch: 45, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.994 D_real: 0.001 D_fake: 0.000 G: 2.556 NCE: 1.267 NCE_Y: 1.856 \n",
            "saving the model at the end of epoch 45, iters 18000\n",
            "End of epoch 45 / 50 \t Time Taken: 174 sec\n",
            "learning rate = 0.0000385\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 46, iters: 100, time: 0.430, data: 0.189) G_GAN: 0.996 D_real: 0.001 D_fake: 0.000 G: 2.780 NCE: 1.276 NCE_Y: 2.291 \n",
            "(epoch: 46, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.006 D_real: 0.001 D_fake: 0.000 G: 2.665 NCE: 1.216 NCE_Y: 2.101 \n",
            "(epoch: 46, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.999 D_real: 0.001 D_fake: 0.000 G: 2.533 NCE: 1.244 NCE_Y: 1.824 \n",
            "(epoch: 46, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.003 D_real: 0.001 D_fake: 0.000 G: 2.599 NCE: 1.206 NCE_Y: 1.986 \n",
            "End of epoch 46 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000308\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 47, iters: 100, time: 0.430, data: 0.202) G_GAN: 1.004 D_real: 0.001 D_fake: 0.000 G: 2.877 NCE: 1.245 NCE_Y: 2.502 \n",
            "(epoch: 47, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.988 D_real: 0.001 D_fake: 0.000 G: 2.426 NCE: 1.214 NCE_Y: 1.663 \n",
            "(epoch: 47, iters: 300, time: 0.430, data: 0.002) G_GAN: 0.996 D_real: 0.001 D_fake: 0.000 G: 2.652 NCE: 1.251 NCE_Y: 2.062 \n",
            "(epoch: 47, iters: 400, time: 0.430, data: 0.002) G_GAN: 1.001 D_real: 0.000 D_fake: 0.000 G: 2.855 NCE: 1.236 NCE_Y: 2.472 \n",
            "End of epoch 47 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000231\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 48, iters: 100, time: 0.430, data: 0.228) G_GAN: 0.996 D_real: 0.000 D_fake: 0.000 G: 2.808 NCE: 1.222 NCE_Y: 2.404 \n",
            "(epoch: 48, iters: 200, time: 0.430, data: 0.002) G_GAN: 0.998 D_real: 0.001 D_fake: 0.000 G: 2.515 NCE: 1.217 NCE_Y: 1.818 \n",
            "(epoch: 48, iters: 300, time: 0.430, data: 0.002) G_GAN: 1.003 D_real: 0.001 D_fake: 0.000 G: 2.975 NCE: 1.202 NCE_Y: 2.742 \n",
            "(epoch: 48, iters: 400, time: 0.431, data: 0.002) G_GAN: 0.999 D_real: 0.000 D_fake: 0.000 G: 2.512 NCE: 1.207 NCE_Y: 1.817 \n",
            "End of epoch 48 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000154\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 49, iters: 100, time: 0.431, data: 0.237) G_GAN: 0.997 D_real: 0.001 D_fake: 0.000 G: 2.448 NCE: 1.210 NCE_Y: 1.692 \n",
            "(epoch: 49, iters: 200, time: 0.430, data: 0.002) G_GAN: 1.000 D_real: 0.001 D_fake: 0.000 G: 2.861 NCE: 1.204 NCE_Y: 2.516 \n",
            "(epoch: 49, iters: 300, time: 0.430, data: 0.001) G_GAN: 1.005 D_real: 0.000 D_fake: 0.000 G: 2.928 NCE: 1.237 NCE_Y: 2.610 \n",
            "(epoch: 49, iters: 400, time: 0.430, data: 0.002) G_GAN: 0.999 D_real: 0.001 D_fake: 0.000 G: 2.754 NCE: 1.241 NCE_Y: 2.270 \n",
            "End of epoch 49 / 50 \t Time Taken: 173 sec\n",
            "learning rate = 0.0000077\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 50, iters: 100, time: 0.431, data: 0.234) G_GAN: 0.990 D_real: 0.001 D_fake: 0.000 G: 2.778 NCE: 1.263 NCE_Y: 2.312 \n",
            "(epoch: 50, iters: 200, time: 0.431, data: 0.002) G_GAN: 0.999 D_real: 0.000 D_fake: 0.000 G: 2.486 NCE: 1.204 NCE_Y: 1.772 \n",
            "(epoch: 50, iters: 300, time: 0.431, data: 0.002) G_GAN: 0.998 D_real: 0.000 D_fake: 0.000 G: 2.979 NCE: 1.233 NCE_Y: 2.729 \n",
            "(epoch: 50, iters: 400, time: 0.431, data: 0.002) G_GAN: 0.986 D_real: 0.001 D_fake: 0.000 G: 2.629 NCE: 1.245 NCE_Y: 2.042 \n",
            "saving the latest model (epoch 50, total_iters 20000)\n",
            "soybean_img2label_CUT\n",
            "saving the model at the end of epoch 50, iters 20000\n",
            "End of epoch 50 / 50 \t Time Taken: 175 sec\n",
            "learning rate = 0.0000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## テスト(Image2Label)"
      ],
      "metadata": {
        "id": "BGAR4q380gUP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBsAHMrLU3rz",
        "outputId": "92f63684-e203-47bd-dfbe-4e2cce135507"
      },
      "source": [
        "# 以下のコードを実行すると，resultsディレクトリが作成され，出力画像が保存される．\n",
        "\n",
        "!python test.py \\\n",
        "  --dataroot ./datasets/image2label \\\n",
        "  --name img2label_CUT \\\n",
        "  --CUT_mode CUT \\\n",
        "  --num_test 500 \\\n",
        "  --phase test \\\n",
        "  --epoch latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                 CUT_mode: CUT                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/soybean_img2label  \t[default: placeholder]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "               easy_label: experiment_name               \n",
            "                    epoch: 35                            \t[default: latest]\n",
            "                     eval: True                          \t[default: False]\n",
            "        flip_equivariance: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "               lambda_GAN: 1.0                           \n",
            "               lambda_NCE: 1.0                           \n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cut                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: soybean_img2label_CUT         \t[default: experiment_name]\n",
            "                    nce_T: 0.07                          \n",
            "                  nce_idt: True                          \n",
            "nce_includes_all_negatives_from_minibatch: False                         \n",
            "               nce_layers: 0,4,8,12,16                   \n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netF: mlp_sample                    \n",
            "                  netF_nc: 256                           \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "             no_antialias: False                         \n",
            "          no_antialias_up: False                         \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                    normD: instance                      \n",
            "                    normG: instance                      \n",
            "              num_patches: 256                           \n",
            "                 num_test: 630                           \t[default: 50]\n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "         random_scale_max: 3.0                           \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "stylegan2_G_num_downsampling: 1                             \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "dataset [UnalignedDataset] was created\n",
            "model [CUTModel] was created\n",
            "creating web directory ./results/soybean_img2label_CUT/test_35\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "loading the model from ./checkpoints/soybean_img2label_CUT/35_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "processing (0000)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0000_0000.jpg']\n",
            "processing (0005)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0000_0005.jpg']\n",
            "processing (0010)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0000_0010.jpg']\n",
            "processing (0015)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0000_0015.jpg']\n",
            "processing (0020)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0000_0020.jpg']\n",
            "processing (0025)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0000_0025.jpg']\n",
            "processing (0030)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0001_0000.jpg']\n",
            "processing (0035)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0001_0005.jpg']\n",
            "processing (0040)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0001_0010.jpg']\n",
            "processing (0045)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0001_0015.jpg']\n",
            "processing (0050)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0001_0020.jpg']\n",
            "processing (0055)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0001_0025.jpg']\n",
            "processing (0060)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0002_0000.jpg']\n",
            "processing (0065)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0002_0005.jpg']\n",
            "processing (0070)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0002_0010.jpg']\n",
            "processing (0075)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0002_0015.jpg']\n",
            "processing (0080)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0002_0020.jpg']\n",
            "processing (0085)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0002_0025.jpg']\n",
            "processing (0090)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0004_0000.jpg']\n",
            "processing (0095)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0004_0005.jpg']\n",
            "processing (0100)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0004_0010.jpg']\n",
            "processing (0105)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0004_0015.jpg']\n",
            "processing (0110)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0004_0020.jpg']\n",
            "processing (0115)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0004_0025.jpg']\n",
            "processing (0120)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0006_0000.jpg']\n",
            "processing (0125)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0006_0005.jpg']\n",
            "processing (0130)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0006_0010.jpg']\n",
            "processing (0135)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0006_0015.jpg']\n",
            "processing (0140)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0006_0020.jpg']\n",
            "processing (0145)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0006_0025.jpg']\n",
            "processing (0150)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0008_0000.jpg']\n",
            "processing (0155)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0008_0005.jpg']\n",
            "processing (0160)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0008_0010.jpg']\n",
            "processing (0165)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0008_0015.jpg']\n",
            "processing (0170)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0008_0020.jpg']\n",
            "processing (0175)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0008_0025.jpg']\n",
            "processing (0180)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0009_0000.jpg']\n",
            "processing (0185)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0009_0005.jpg']\n",
            "processing (0190)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0009_0010.jpg']\n",
            "processing (0195)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0009_0015.jpg']\n",
            "processing (0200)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0009_0020.jpg']\n",
            "processing (0205)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0009_0025.jpg']\n",
            "processing (0210)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0040_0000.jpg']\n",
            "processing (0215)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0040_0005.jpg']\n",
            "processing (0220)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0040_0010.jpg']\n",
            "processing (0225)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0040_0015.jpg']\n",
            "processing (0230)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0040_0020.jpg']\n",
            "processing (0235)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0040_0025.jpg']\n",
            "processing (0240)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0042_0000.jpg']\n",
            "processing (0245)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0042_0005.jpg']\n",
            "processing (0250)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0042_0010.jpg']\n",
            "processing (0255)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0042_0015.jpg']\n",
            "processing (0260)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0042_0020.jpg']\n",
            "processing (0265)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0042_0025.jpg']\n",
            "processing (0270)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0048_0000.jpg']\n",
            "processing (0275)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0048_0005.jpg']\n",
            "processing (0280)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0048_0010.jpg']\n",
            "processing (0285)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0048_0015.jpg']\n",
            "processing (0290)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0048_0020.jpg']\n",
            "processing (0295)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0048_0025.jpg']\n",
            "processing (0300)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0086_0000.jpg']\n",
            "processing (0305)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0086_0005.jpg']\n",
            "processing (0310)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0086_0010.jpg']\n",
            "processing (0315)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0086_0015.jpg']\n",
            "processing (0320)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0086_0020.jpg']\n",
            "processing (0325)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0086_0025.jpg']\n",
            "processing (0330)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0243_0000.jpg']\n",
            "processing (0335)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0243_0005.jpg']\n",
            "processing (0340)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0243_0010.jpg']\n",
            "processing (0345)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0243_0015.jpg']\n",
            "processing (0350)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0243_0020.jpg']\n",
            "processing (0355)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0243_0025.jpg']\n",
            "processing (0360)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0338_0000.jpg']\n",
            "processing (0365)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0338_0005.jpg']\n",
            "processing (0370)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0338_0010.jpg']\n",
            "processing (0375)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0338_0015.jpg']\n",
            "processing (0380)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0338_0020.jpg']\n",
            "processing (0385)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0338_0025.jpg']\n",
            "processing (0390)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0349_0000.jpg']\n",
            "processing (0395)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0349_0005.jpg']\n",
            "processing (0400)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0349_0010.jpg']\n",
            "processing (0405)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0349_0015.jpg']\n",
            "processing (0410)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0349_0020.jpg']\n",
            "processing (0415)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0349_0025.jpg']\n",
            "processing (0420)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0355_0000.jpg']\n",
            "processing (0425)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0355_0005.jpg']\n",
            "processing (0430)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0355_0010.jpg']\n",
            "processing (0435)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0355_0015.jpg']\n",
            "processing (0440)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0355_0020.jpg']\n",
            "processing (0445)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0355_0025.jpg']\n",
            "processing (0450)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0356_0000.jpg']\n",
            "processing (0455)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0356_0005.jpg']\n",
            "processing (0460)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0356_0010.jpg']\n",
            "processing (0465)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0356_0015.jpg']\n",
            "processing (0470)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0356_0020.jpg']\n",
            "processing (0475)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0356_0025.jpg']\n",
            "processing (0480)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0357_0000.jpg']\n",
            "processing (0485)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0357_0005.jpg']\n",
            "processing (0490)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0357_0010.jpg']\n",
            "processing (0495)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0357_0015.jpg']\n",
            "processing (0500)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0357_0020.jpg']\n",
            "processing (0505)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0357_0025.jpg']\n",
            "processing (0510)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0365_0000.jpg']\n",
            "processing (0515)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0365_0005.jpg']\n",
            "processing (0520)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0365_0010.jpg']\n",
            "processing (0525)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0365_0015.jpg']\n",
            "processing (0530)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0365_0020.jpg']\n",
            "processing (0535)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0365_0025.jpg']\n",
            "processing (0540)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0368_0000.jpg']\n",
            "processing (0545)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0368_0005.jpg']\n",
            "processing (0550)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0368_0010.jpg']\n",
            "processing (0555)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0368_0015.jpg']\n",
            "processing (0560)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0368_0020.jpg']\n",
            "processing (0565)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0368_0025.jpg']\n",
            "processing (0570)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0372_0000.jpg']\n",
            "processing (0575)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0372_0005.jpg']\n",
            "processing (0580)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0372_0010.jpg']\n",
            "processing (0585)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0372_0015.jpg']\n",
            "processing (0590)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0372_0020.jpg']\n",
            "processing (0595)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0372_0025.jpg']\n",
            "processing (0600)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0391_0000.jpg']\n",
            "processing (0605)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0391_0005.jpg']\n",
            "processing (0610)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0391_0010.jpg']\n",
            "processing (0615)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0391_0015.jpg']\n",
            "processing (0620)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0391_0020.jpg']\n",
            "processing (0625)-th image... ['./datasets/soybean_img2label/testA/trainval_img_0200_0391_0025.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FIDの計算\n"
      ],
      "metadata": {
        "id": "5qXr6LPW1s0E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNkv0kWtU4Vy",
        "outputId": "2327293b-6e5f-47f6-dee9-0f0759cde8b0"
      },
      "source": [
        "# 以下のコードを実行すると，FIDが出力される．\n",
        "# 第一引数にラベル画像(事前に用意したもの)，第二引数に生成画像(テストで生成された画像)のディレクトリを指定．\n",
        "\n",
        "!python -m pytorch_fid ./datasets/image2label/testB/ ./results/image2label_CUT/test_latest/images/fake_B/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4/4 [00:01<00:00,  2.16it/s]\n",
            "100% 4/4 [00:01<00:00,  2.46it/s]\n",
            "FID:  207.07649349433092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDAewe_kQYQa",
        "outputId": "a2414014-2c2a-48d7-f8fa-2445db5e4799"
      },
      "source": [
        "# テストコードとFIDをスクリプトでたたく．\n",
        "\n",
        "%% bash\n",
        "touch ./result/image2label/FID.txt\n",
        "echo \"${epoch},${FID}\\n\" >> ./result/image2label/FID.txt\n",
        "\n",
        "epochs = [25, 50, 75, 100]\n",
        "for num in $(epochs)\n",
        "do\n",
        "  echo \"${num}\" >> ./result/image2label/FID.txt\n",
        "  python --dataroot ./datasets/image2label --name img2label_CUT --CUT_mode CUT --num_test 500 --phase test --epoch ${num}\n",
        "  python -m pytorch_fid ./datasets/image2label/testB/ ./results/img2gt_CUT/train_${num}/images/fake_B/ >> ./result/image2label/FID.txt\n",
        "done"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "100% 1/1 [00:00<00:00,  1.02it/s]\n",
            "FID:  181.53864521865927\n"
          ]
        }
      ]
    }
  ]
}